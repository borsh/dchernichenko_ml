{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "Keras — открытая нейросетевая библиотека, написанная на языке Python. Она представляет собой надстройку над фреймворками Deeplearning4j, TensorFlow и Theano.[1][2] Нацелена на оперативную работу с сетями глубинного обучения, при этом спроектирована так, чтобы быть компактной, модульной и расширяемой. Она была создана как часть исследовательских усилий проекта ONEIROS (англ. Open-ended Neuro-Electronic Intelligent Robot Operating System),[3] а ее основным автором и поддерживающим является Франсуа Шолле (фр. François Chollet), инженер Google.\n",
    "\n",
    "Планировалось что Google будет поддерживать Keras в основной библиотеке TensorFlow, однако Шолле выделил Keras в отдельную надстройку, так как согласно концепции Keras является скорее интерфейсом, чем сквозной системой машинного обучения. Keras предоставляет высокоуровневый, более интуитивный набор абстракций, который делает простым формирования нейронных сетей не зависимо от используемой на нижнем уровне библиотеки научных вычислений.[4] Microsoft работает над добавлением к Keras и нижнеуровневых библиотек CNTK[en].[5]\n",
    "\n",
    "https://ru.wikipedia.org/wiki/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/develop/ml/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST \n",
    "Загрузим MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовые и тренировачные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train,X_test,  y_test = X[:60000], y[:60000], X[60000:], y[60000:]\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train2D = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test2D = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdd2c9a8f28>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train2D[20000,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "кодируем метки (label) в K-мерный массив, необходимый шаг для тренировки, когда результатом является метка. Для данных MNIST метка - число от 0 до 9 - цифра, изображенная на изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense neural network DNN\n",
    "Строим нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=300, activation='relu', input_dim=784))\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=300))\n",
    "model.add(Dense(units=32, activation='relu', input_dim=100))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.7860 - acc: 0.8464\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 2.1566 - acc: 0.8251\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 4.0282 - acc: 0.7376\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 7.2967 - acc: 0.5442\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 9.4957 - acc: 0.4096\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 9.6232 - acc: 0.4021\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 9.1808 - acc: 0.4297\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 9.1386 - acc: 0.4325\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 9.0971 - acc: 0.4350\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 9.3657 - acc: 0.4185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd1c1318d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если долго ждать, можно загрузить из файла (сначала в верхнем меню выберите Kernel/Interupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(os.path.expanduser('~/model/keras_mnist_dnn.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4350170964811696, 0.9484]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.expanduser('~/model/keras_mnist_dnn.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим сеть\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " и тренируем её"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      " 1792/60000 [..............................] - ETA: 3:30 - loss: 4.2006 - acc: 0.2081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2b14d8457d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_train2D, Y_train,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m           )\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/ml/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train2D, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если долго ждать, можно загрузить уже натренированную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(os.path.expanduser('~/model/keras_mnist_cnn.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 849us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9904"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test2D, Y_test, batch_size=128)\n",
    "loss_and_metrics[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.expanduser('~/model/keras_mnist_cnn.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "classes=['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'автомобиль'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "idx = 10000\n",
    "plt.imshow(x_train[idx,:,:])\n",
    "classes[np.argmax(y_train[idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренировка займет некторое время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 222s 4ms/step - loss: 1.8477 - acc: 0.3250 - val_loss: 1.5564 - val_acc: 0.4421\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 1.5178 - acc: 0.4503 - val_loss: 1.3653 - val_acc: 0.5206\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 1.3755 - acc: 0.5046 - val_loss: 1.2502 - val_acc: 0.5531\n",
      "Epoch 4/100\n",
      "13184/50000 [======>.......................] - ETA: 2:25 - loss: 1.2811 - acc: 0.5470"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9dc92f1edbef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_and_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_and_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "loss_and_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.expanduser('~/model/keras_cifar10.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать нейронную сеть, которая бы позволяла предсказать стоимость дома на основе датасета california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15480, 8), (5160, 8), (15480,), (5160,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import california_housing\n",
    "data = california_housing.fetch_california_housing()\n",
    "X, y = data['data'], data['target']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсказка:\n",
    "Эта задача на регрессию. Для того, чтобы определить нейронную сеть, которая бы решала эту проблему, последний слой должен быть с линейной активаторной функцией. \n",
    "\n",
    "    model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
